{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Does NGD converge to more complex minima according to the RLCT (Real Log Canonical Threshold)?**\n",
    "\n",
    "This notebook aims to test the above claim, using developmental interpretability methods.\n",
    "\n",
    "We hypothesise that NGD will consistently have a higher RLCT, because it premultiplies the gradient used for gradient descent by the inverse of the Fisher Information Matrix.\n",
    "\n",
    "SLT proposes that models converge to singularities, where the Fisher Information Matrix is non-invertable. Hence, when near a singularity, the inverse of the FIM will blow up as its determinant is close to 0. Therefore, NGD will \"jump away\" from the singularity, instead favouring more complex, less singular minima.\n",
    "\n",
    "#### **Methodology**\n",
    "- Choose between DNN (dense neural network) and CNN (convolutional neural network)\n",
    "- Vary hidden nodes and hidden layers for DNN (depth and width)\n",
    "- Vary number of convolutional layers for CNN.\n",
    "- Estimate Hessian rank using `PyHessian` module.\n",
    "- Estimate RLCT using `devinterp` library.\n",
    "\n",
    "#### **Instructions**\n",
    "\n",
    "To produce your own results, go to `args_ngd_sgd.json`. The following parameters can be adjusted:\n",
    "- `model_type (str)`  : `dnn` (deep network), `cnn` (convolutional network)\n",
    "- `optimizer (str)` : `sgd`, `ngd`, or `both` (performs analysis on both optimizers)\n",
    "- `hessian (bool)` : `true`, `false` (does Hessian rank analysis if enabled)\n",
    "- `num_epochs (int)` : total number of training epochs\n",
    "- `cut_off_epochs (int)` : the epoch number at which the optimiser is swapped (make this equal to `num_epochs`) if you want no swapping\n",
    "- `sgd_lr (float)` : sgd learning rate for training\n",
    "- `ngd_lr (float)` : ngd learning rate for training\n",
    "- `alpha (float)` : smoothing constant for estimation of FIM for NGD\n",
    "- `momentum (float)` : momentum used in SGD and NGD\n",
    "- `nesterov (bool)` : enable Nesterov momentum for NGD / SGD\n",
    "- `batch_size (int)` : batch size for train / validation dataloaders\n",
    "- `num_workers (int)` : number of GPU workers for data loading (keep this at around 6, vary depending on your hardware)\n",
    "- `dataset (str)` : `mnist`, `cifar10` (dataset to use for training)\n",
    "- `num_hessian_batches (int)` : number of batches used for estimation of Hessian\n",
    "- `sampler (str)` : `sgld`, `sgnht` (optimiser to use for RLCT estimation)\n",
    "- `num_chains (int)` : number of chains to use in RLCT estimation (higher leads to more accurate RLCT estimate)\n",
    "- `num_draws (int)` : number of optimizer steps in RLCT estimation (should be high enough such that chain RLCT converges - check convergence plot)\n",
    "- `localization (float)` : higher localization more strongly restricts optimizer to neighbourhood of model weights (stops RLCT estimator from going straight to minima)\n",
    "- `sampler_lr (float)` : learning rate for sampler for RLCT estimation\n",
    "\n",
    "You can run the notebook from the terminal using the following command:\n",
    "```bash\n",
    "jupyter nbconvert --to notebook --execute --inplace ./experiments/eval_ngd_sgd.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **0. Import libraries**\n",
    "\n",
    "The `NGD` module is used for implementing Natural Gradient Descent efficiently. It approximates the Fisher Information Matrix to do this.\n",
    "The `devinterp` library is used for estimation of the LLC (local learning coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:12:56.173293Z",
     "iopub.status.busy": "2024-03-26T15:12:56.173293Z",
     "iopub.status.idle": "2024-03-26T15:13:02.788565Z",
     "shell.execute_reply": "2024-03-26T15:13:02.788565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device in use: cuda\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import freeze_support\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import pickle\n",
    "import pprint\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "from devinterp.slt import estimate_learning_coeff_with_summary\n",
    "from devinterp.optim import SGLD, SGNHT\n",
    "from devinterp.slt import sample, OnlineLLCEstimator\n",
    "from devinterp.slt.wbic import OnlineWBICEstimator\n",
    "from devinterp.slt.mala import MalaAcceptanceRate\n",
    "from devinterp.utils import plot_trace, optimal_temperature\n",
    "\n",
    "from approxngd import KFAC\n",
    "from PyHessian.pyhessian import *\n",
    "from PyHessian.density_plot import *\n",
    "from nngeometry.metrics import FIM\n",
    "from nngeometry.object import PMatKFAC, PMatDiag, PVector\n",
    "\n",
    "from utils_general import *\n",
    "from utils_hessian_fim import *\n",
    "from networks import *\n",
    "from ngd import NGD\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.colors\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "device = \"cuda\" if t.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device in use: {device}\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Import data for training**\n",
    "\n",
    "We import our dataset for training. We use a helper function, `build_data_loaders` for this, which allows us to choose between MNIST and CIFAR10. \n",
    "\n",
    "We specify three dictionaries, `hp` = hyperparameters, `data_args` = arguments for dataloading, `devinterp_args` = arguments for LLC and WBIC estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:13:02.790210Z",
     "iopub.status.busy": "2024-03-26T15:13:02.790210Z",
     "iopub.status.idle": "2024-03-26T15:13:02.804209Z",
     "shell.execute_reply": "2024-03-26T15:13:02.804209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERPARAMETERS\n",
      "{'alpha': 0,\n",
      " 'cut_off_epochs': 10,\n",
      " 'eta': 0.9,\n",
      " 'experiment_type': 'swap',\n",
      " 'hessian': True,\n",
      " 'hidden_conv_layers': [1, 2, 3],\n",
      " 'hidden_layers': [2],\n",
      " 'hidden_nodes': [128],\n",
      " 'model_type': 'dnn',\n",
      " 'momentum': 0.9,\n",
      " 'nesterov': True,\n",
      " 'ngd_lr': 0.01,\n",
      " 'num_epochs': 30,\n",
      " 'optimizer': 'both',\n",
      " 'seed': 43,\n",
      " 'sgd_lr': 0.01}\n",
      "DATA ARGS\n",
      "{'batch_size': 128,\n",
      " 'dataset': 'mnist',\n",
      " 'num_hessian_batches': 1,\n",
      " 'num_workers': 6}\n",
      "DEVINTERP ARGS\n",
      "{'localization': 100.0,\n",
      " 'num_chains': 1,\n",
      " 'num_draws': 1000,\n",
      " 'sampler': 'sgld',\n",
      " 'sampler_lr': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# Load experiment args\n",
    "\n",
    "with open(\"args_ngd_sgd.json\", \"r\") as file:\n",
    "    args = json.load(file) \n",
    "\n",
    "hp, data_args, devinterp_args = args\n",
    "\n",
    "print(\"HYPERPARAMETERS\")\n",
    "pprint.pprint(hp)\n",
    "\n",
    "print(\"DATA ARGS\")\n",
    "pprint.pprint(data_args)\n",
    "\n",
    "print(\"DEVINTERP ARGS\")\n",
    "pprint.pprint(devinterp_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e230ec58b0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for weight initialisation (for reproducibility of results and to ensure NGD/SGD start from same point in loss landscape)\n",
    "\n",
    "t.manual_seed(hp[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:13:02.805683Z",
     "iopub.status.busy": "2024-03-26T15:13:02.805683Z",
     "iopub.status.idle": "2024-03-26T15:13:02.852504Z",
     "shell.execute_reply": "2024-03-26T15:13:02.851934Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader = build_data_loaders(data_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **2. Training models**\n",
    "\n",
    "Choose to train either a DNN or CNN.\n",
    "\n",
    "This code produces a dictionary where each key describes the model itself, e.g. \"DNN 4 HL, 256 HN\".\n",
    "\n",
    "The values are each a list containing the first model. As models are trained, each epoch the trained model will be added to this list so we can record the model history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:13:02.855565Z",
     "iopub.status.busy": "2024-03-26T15:13:02.855565Z",
     "iopub.status.idle": "2024-03-26T15:13:02.930892Z",
     "shell.execute_reply": "2024-03-26T15:13:02.930892Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialise models dependent on arguments\n",
    "\n",
    "models = {}\n",
    "optimizers = [\"sgd\", \"ngd\"] if hp[\"optimizer\"] == \"both\" else [hp[\"optimizer\"]]\n",
    "\n",
    "if hp[\"model_type\"] == \"dnn\":\n",
    "    hidden_nodes = hp[\"hidden_nodes\"]\n",
    "    hidden_layers = hp[\"hidden_layers\"]\n",
    "    for hidden_node, hidden_layer in zip(hidden_nodes, hidden_layers):\n",
    "        title = f\"DNN {hidden_layer} HL, {hidden_node} HN\"\n",
    "        if data_args[\"dataset\"] == \"mnist\":\n",
    "            model = LinearMNIST(hidden_layers=hidden_layer, hidden_nodes=hidden_node).to(device)\n",
    "        elif data_args[\"dataset\"] == \"cifar10\":\n",
    "            model = LinearCIFAR10(hidden_layers=hidden_layer, hidden_nodes=hidden_node).to(device)\n",
    "        models[title] = {optim : [copy.deepcopy(model)] for optim in optimizers}\n",
    "elif hp[\"model_type\"] == \"cnn\":\n",
    "    hidden_conv_layers = hp[\"hidden_conv_layers\"]\n",
    "    for hidden_conv_layer in hidden_conv_layers:\n",
    "        title = f\"CNN {hidden_conv_layer} HCL\"\n",
    "        if data_args[\"dataset\"] == \"mnist\":\n",
    "            model = CnnMNIST(hidden_conv_layers=hidden_conv_layer).to(device)\n",
    "        elif data_args[\"dataset\"] == \"cifar10\":\n",
    "            model = CnnCIFAR10(hidden_conv_layers=hidden_conv_layer).to(device)\n",
    "        models[title] = {optim : [copy.deepcopy(model)] for optim in optimizers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:13:02.930892Z",
     "iopub.status.busy": "2024-03-26T15:13:02.930892Z",
     "iopub.status.idle": "2024-03-26T15:13:02.947470Z",
     "shell.execute_reply": "2024-03-26T15:13:02.946899Z"
    }
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT 1: Train models independently for num_epochs with SGD and NGD\n",
    "\n",
    "if hp[\"experiment_type\"] == \"standard\":\n",
    "    train_losses = {}\n",
    "    val_losses = {}\n",
    "    update_norms = {}\n",
    "    all_update_norms = {}\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for title, model in models.items():\n",
    "\n",
    "        # Store list for SGD losses, NGD losses, for train and val\n",
    "        model_train_losses = {optim : [] for optim in optimizers}\n",
    "        model_val_losses = {optim : [] for optim in optimizers}\n",
    "        model_update_norms = {optim : [] for optim in optimizers}\n",
    "        model_all_update_norms = {optim : [] for optim in optimizers}\n",
    "\n",
    "        for optim in optimizers:\n",
    "            state = copy.deepcopy(model[optim][0])\n",
    "            if optim == \"sgd\":\n",
    "                optimizer = t.optim.SGD(\n",
    "                    params=state.parameters(),\n",
    "                    lr=hp[\"sgd_lr\"],\n",
    "                    momentum=hp[\"momentum\"],\n",
    "                    nesterov=hp[\"nesterov\"],\n",
    "                )\n",
    "            elif optim == \"ngd\":\n",
    "                optimizer = NGD(\n",
    "                    params=state.parameters(),\n",
    "                    lr=hp[\"ngd_lr\"],\n",
    "                    alpha=hp[\"alpha\"],\n",
    "                    eta=hp[\"eta\"],\n",
    "                    momentum=hp[\"momentum\"],\n",
    "                    nesterov=hp[\"nesterov\"],\n",
    "                )\n",
    "            print(f\"TRAINING MODEL: {title} | OPTIMISER: {optim}\")\n",
    "            initial_train_loss = evaluate(state, train_loader, criterion, device)\n",
    "            initial_val_loss = evaluate(state, test_loader, criterion, device)\n",
    "            model_train_losses[optim].append(initial_train_loss)\n",
    "            model_val_losses[optim].append(initial_val_loss)\n",
    "            for epoch in range(1, hp[\"cut_off_epochs\"]+1):\n",
    "                train_loss, update_norm, _, epoch_update_norms = train_one_epoch(state, train_loader, optimizer, criterion, device)\n",
    "                val_loss = evaluate(state, test_loader, criterion, device)\n",
    "                model_train_losses[optim].append(train_loss)\n",
    "                model_update_norms[optim].append(update_norm)\n",
    "                model_val_losses[optim].append(val_loss)\n",
    "                model_all_update_norms[optim] += epoch_update_norms\n",
    "                model[optim].append(copy.deepcopy(state))\n",
    "                print(f\"Epoch {epoch}/{hp['num_epochs']}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "\n",
    "        # Save train/val loss dictionaries to the right model key\n",
    "        train_losses[title] = model_train_losses\n",
    "        val_losses[title] = model_val_losses\n",
    "        update_norms[title] = model_update_norms\n",
    "        all_update_norms[title] = model_all_update_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:13:02.950652Z",
     "iopub.status.busy": "2024-03-26T15:13:02.950375Z",
     "iopub.status.idle": "2024-03-26T15:16:55.505733Z",
     "shell.execute_reply": "2024-03-26T15:16:55.505612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING MODEL: DNN 2 HL, 128 HN | OPTIMISER: SGD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 107.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: train_loss=0.4351, val_loss=0.1924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 111.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: train_loss=0.1624, val_loss=0.1306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 112.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30: train_loss=0.1111, val_loss=0.1048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:04<00:00, 97.15it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30: train_loss=0.0835, val_loss=0.0878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 77.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30: train_loss=0.0666, val_loss=0.0800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30: train_loss=0.0540, val_loss=0.0756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 76.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: train_loss=0.0444, val_loss=0.0711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 79.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30: train_loss=0.0357, val_loss=0.0679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30: train_loss=0.0303, val_loss=0.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30: train_loss=0.0255, val_loss=0.0693\n",
      "Training from model checkpoint with SGD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: train_loss=0.0210, val_loss=0.0767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: train_loss=0.0169, val_loss=0.0730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: train_loss=0.0143, val_loss=0.0707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: train_loss=0.0117, val_loss=0.0706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: train_loss=0.0093, val_loss=0.0717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 81.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: train_loss=0.0083, val_loss=0.0743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: train_loss=0.0065, val_loss=0.0771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 81.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: train_loss=0.0052, val_loss=0.0747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: train_loss=0.0044, val_loss=0.0768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 80.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: train_loss=0.0037, val_loss=0.0764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 80.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: train_loss=0.0029, val_loss=0.0748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:06<00:00, 76.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: train_loss=0.0024, val_loss=0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: train_loss=0.0021, val_loss=0.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 81.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: train_loss=0.0018, val_loss=0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: train_loss=0.0016, val_loss=0.0791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 81.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: train_loss=0.0014, val_loss=0.0797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: train_loss=0.0013, val_loss=0.0795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 82.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: train_loss=0.0012, val_loss=0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 81.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: train_loss=0.0011, val_loss=0.0815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:05<00:00, 83.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: train_loss=0.0011, val_loss=0.0828\n",
      "Training from model checkpoint with NGD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/469 [00:00<?, ?it/s]c:\\Users\\moosa\\OneDrive\\Documents\\windows_dev\\ngd_with_slt\\experiments\\..\\ngd.py:586: UserWarning: This overload of add is deprecated:\n",
      "\tadd(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd(Tensor other, *, Number alpha) (Triggered internally at ..\\torch\\csrc\\utils\\python_arg_parser.cpp:1630.)\n",
      "  d_p = d_p.add(momentum, buf)\n",
      "100%|██████████| 469/469 [00:19<00:00, 24.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30: train_loss=171455814.5441, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30: train_loss=2.3013, val_loss=2.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30: train_loss=2.3014, val_loss=2.3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 24.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: train_loss=2.3014, val_loss=2.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30: train_loss=2.3014, val_loss=2.3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30: train_loss=2.3015, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30: train_loss=2.3014, val_loss=2.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30: train_loss=2.3014, val_loss=2.3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30: train_loss=2.3013, val_loss=2.3013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: train_loss=2.3014, val_loss=2.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30: train_loss=2.3014, val_loss=2.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30: train_loss=2.3014, val_loss=2.3010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30: train_loss=2.3014, val_loss=2.3012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:18<00:00, 25.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30: train_loss=2.3014, val_loss=2.3011\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 2: Train to convergence with SGD, then continue with SGD and NGD and compare\n",
    "\n",
    "if hp[\"experiment_type\"] == \"swap\":\n",
    "    train_losses = {}\n",
    "    val_losses = {}\n",
    "    update_norms = {}\n",
    "    all_update_norms = {}\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for title, model in models.items():\n",
    "\n",
    "        del model[\"ngd\"][0]\n",
    "\n",
    "        model_train_losses = {\"sgd\" : [], \"ngd\" : [None for i in range(hp[\"cut_off_epochs\"]+1)]}\n",
    "        model_val_losses = {\"sgd\" : [], \"ngd\" : [None for i in range(hp[\"cut_off_epochs\"]+1)]}\n",
    "        model_update_norms = {\"sgd\" : [], \"ngd\" : [None for i in range(hp[\"cut_off_epochs\"]+1)]}\n",
    "        model_all_update_norms = {\"sgd\" : [], \"ngd\" : [None for i in range(len(train_loader)*hp[\"cut_off_epochs\"])]}\n",
    "\n",
    "        state = copy.deepcopy(model[\"sgd\"][0])\n",
    "        optimizer = t.optim.SGD(\n",
    "            params=state.parameters(),\n",
    "            lr=hp[\"sgd_lr\"],\n",
    "            momentum=hp[\"momentum\"],\n",
    "            nesterov=hp[\"nesterov\"],\n",
    "        )\n",
    "    \n",
    "        print(f\"TRAINING MODEL: {title} | OPTIMISER: SGD\")\n",
    "        initial_train_loss = evaluate(state, train_loader, criterion, device)\n",
    "        initial_val_loss = evaluate(state, test_loader, criterion, device)\n",
    "        model_train_losses[\"sgd\"].append(initial_train_loss)\n",
    "        model_val_losses[\"sgd\"].append(initial_val_loss)\n",
    "        for epoch in range(1, hp[\"cut_off_epochs\"]+1):\n",
    "            train_loss, update_norm, _, epoch_update_norms = train_one_epoch(state, train_loader, optimizer, criterion, device)\n",
    "            val_loss = evaluate(state, test_loader, criterion, device)\n",
    "            model_train_losses[\"sgd\"].append(train_loss)\n",
    "            model_update_norms[\"sgd\"].append(update_norm)\n",
    "            model_val_losses[\"sgd\"].append(val_loss)\n",
    "            model_all_update_norms[\"sgd\"] += epoch_update_norms\n",
    "            model[\"sgd\"].append(copy.deepcopy(state))\n",
    "            print(f\"Epoch {epoch}/{hp['num_epochs']}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "\n",
    "\n",
    "        # Train with SGD\n",
    "        print(\"Training from model checkpoint with SGD.\")\n",
    "        state = copy.deepcopy(model[\"sgd\"][hp[\"cut_off_epochs\"]])\n",
    "        optim_sgd = t.optim.SGD(\n",
    "            params=state.parameters(),\n",
    "            lr=hp[\"sgd_lr\"],\n",
    "            momentum=hp[\"momentum\"],\n",
    "            nesterov=hp[\"nesterov\"],\n",
    "        )\n",
    "        for epoch in range(hp[\"cut_off_epochs\"]+1, hp[\"num_epochs\"]+1):\n",
    "            train_loss, update_norm, _, epoch_update_norms = train_one_epoch(state, train_loader, optim_sgd, criterion, device)\n",
    "            val_loss = evaluate(state, test_loader, criterion, device)\n",
    "            model_train_losses[\"sgd\"].append(train_loss)\n",
    "            model_update_norms[\"sgd\"].append(update_norm)\n",
    "            model_val_losses[\"sgd\"].append(val_loss)\n",
    "            model_all_update_norms[\"sgd\"] += epoch_update_norms\n",
    "            model[\"sgd\"].append(copy.deepcopy(state))\n",
    "            print(f\"Epoch {epoch}/{hp['num_epochs']}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "        \n",
    "        # Train with NGD\n",
    "        print(\"Training from model checkpoint with NGD.\")\n",
    "        state = copy.deepcopy(model[\"sgd\"][hp[\"cut_off_epochs\"]])\n",
    "        optim_ngd = NGD(\n",
    "            params=state.parameters(),\n",
    "            lr=hp[\"ngd_lr\"],\n",
    "            alpha=hp[\"alpha\"],\n",
    "            eta=hp[\"eta\"],\n",
    "            momentum=hp[\"momentum\"],\n",
    "            nesterov=hp[\"nesterov\"],\n",
    "        )\n",
    "        for epoch in range(hp[\"cut_off_epochs\"]+1, hp[\"num_epochs\"]+1):\n",
    "            train_loss, update_norm, _, epoch_update_norms = train_one_epoch(state, train_loader, optim_ngd, criterion, device)\n",
    "            val_loss = evaluate(state, test_loader, criterion, device)\n",
    "            model_train_losses[\"ngd\"].append(train_loss)\n",
    "            model_update_norms[\"ngd\"].append(update_norm)\n",
    "            model_val_losses[\"ngd\"].append(val_loss)\n",
    "            model_all_update_norms[\"ngd\"] += epoch_update_norms\n",
    "            model[\"ngd\"].append(copy.deepcopy(state))\n",
    "            print(f\"Epoch {epoch}/{hp['num_epochs']}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "\n",
    "        # Save train/val loss dictionaries to the right model key\n",
    "        train_losses[title] = model_train_losses\n",
    "        val_losses[title] = model_val_losses\n",
    "        update_norms[title] = model_update_norms\n",
    "        all_update_norms[title] = model_all_update_norms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:16:55.509308Z",
     "iopub.status.busy": "2024-03-26T15:16:55.507910Z",
     "iopub.status.idle": "2024-03-26T15:16:55.521559Z",
     "shell.execute_reply": "2024-03-26T15:16:55.521559Z"
    }
   },
   "outputs": [],
   "source": [
    "# If we are doing the swap experiment, fill in the first hp[\"cut_off_epochs\"] models with None\n",
    "\n",
    "if hp[\"experiment_type\"] == \"swap\":\n",
    "    none_models = [None for i in range(hp[\"cut_off_epochs\"]+1)]\n",
    "    for title, model in models.items():\n",
    "        model[\"ngd\"] = none_models + model[\"ngd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3. Visualising training / validation loss results**\n",
    "\n",
    "Check that the models all converged.\n",
    "\n",
    "Displays training and testing data for each model separately, with 4 traces on each graph.\n",
    "\n",
    "The traces are: SGD training, SGD testing, NGD training, NGD testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:16:55.525234Z",
     "iopub.status.busy": "2024-03-26T15:16:55.523706Z",
     "iopub.status.idle": "2024-03-26T15:16:55.950693Z",
     "shell.execute_reply": "2024-03-26T15:16:55.949585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "rgb(0, 0, 255)"
         },
         "mode": "lines+markers",
         "name": "sgd Train",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "xaxis": "x",
         "y": [
          2.306239828117875,
          0.4350754162395941,
          0.16241467493111644,
          0.1111315295402048,
          0.08345061996137537,
          0.06658519413679648,
          0.05400819854060216,
          0.044422786217182875,
          0.03566711515223961,
          0.030266867936161884,
          0.025455798888737873,
          0.02099051670894138,
          0.016912746397571874,
          0.014291722948766196,
          0.011683011951266543,
          0.009327230572418523,
          0.008334463025738141,
          0.0065477768541065485,
          0.005165704038936887,
          0.004395810351682219,
          0.003714844197986016,
          0.002865200421821548,
          0.002439958370116446,
          0.0020934620618707003,
          0.0017918825683302865,
          0.0016244450554391667,
          0.0014169396611079742,
          0.0013165967840695634,
          0.0012265884961806554,
          0.0011286536947566408,
          0.001057688010091246
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "rgb(0, 0, 255)",
          "dash": "dot"
         },
         "mode": "lines+markers",
         "name": "sgd Validation",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "xaxis": "x",
         "y": [
          2.3056092081190664,
          0.1923641898386369,
          0.1305875092791983,
          0.10477304743025216,
          0.08780567313962957,
          0.08001146277322882,
          0.0756443121774075,
          0.07106651522475589,
          0.06788218563239833,
          0.07001284731233705,
          0.06931410093579583,
          0.07667166363304964,
          0.07303231765086544,
          0.07074553407456054,
          0.07061666593934988,
          0.07168661010379039,
          0.07434580457648056,
          0.07705147030081874,
          0.07471242775223984,
          0.07682549841227321,
          0.07637268024345874,
          0.07475951746875834,
          0.07911155787150728,
          0.07807991699347797,
          0.0784184271701691,
          0.07911201389802218,
          0.07968735031952263,
          0.07948804667637001,
          0.08111762054166527,
          0.08150620158324537,
          0.08278422243130437
         ],
         "yaxis": "y2"
        },
        {
         "line": {
          "color": "rgb(255, 0, 0)"
         },
         "mode": "lines+markers",
         "name": "ngd Train",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "xaxis": "x",
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          171455814.5440611,
          2.3013247106629393,
          2.3014156066024225,
          2.30140111237955,
          2.301354481467306,
          2.3014358157542216,
          2.3014696152733842,
          2.30142893720029,
          2.3013642779799666,
          2.301401182532565,
          2.3014318155073155,
          2.301301638963126,
          2.301398240172787,
          2.3013639958428422,
          2.301418379679926,
          2.3014083035719164,
          2.301411514343229,
          2.301372028363031,
          2.301390074463541,
          2.30140155109007
         ],
         "yaxis": "y"
        },
        {
         "line": {
          "color": "rgb(255, 0, 0)",
          "dash": "dot"
         },
         "mode": "lines+markers",
         "name": "ngd Validation",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30
         ],
         "xaxis": "x",
         "y": [
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          null,
          2.301138352744187,
          2.301296478585352,
          2.301230584518819,
          2.301053113575223,
          2.3013446210305903,
          2.3012036220936833,
          2.30111611643924,
          2.3010652517970605,
          2.3010105000266545,
          2.3010526608817186,
          2.3011855656587623,
          2.3013094195836707,
          2.3010297153569477,
          2.301351957683322,
          2.3010926880413973,
          2.301038310497622,
          2.3010805136040795,
          2.301227002204219,
          2.301063938985897,
          2.30114386956903
         ],
         "yaxis": "y2"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "DNN 2 HL, 128 HN training / validation loss"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.94
         ],
         "dtick": 1,
         "tick0": 0,
         "tickmode": "linear",
         "title": {
          "text": "Epoch"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Training Loss"
         },
         "type": "linear"
        },
        "yaxis2": {
         "anchor": "x",
         "overlaying": "y",
         "side": "right",
         "title": {
          "text": "Validation Loss"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display training / val data for all models for NGD / SGD\n",
    "\n",
    "epochs = np.arange(1, hp[\"num_epochs\"]+1)\n",
    "\n",
    "loss_figures = {}\n",
    "\n",
    "color_cycle = ['rgb(0, 0, 255)', 'rgb(255, 0, 0)']\n",
    "\n",
    "for title in models.keys():\n",
    "    loss_fig = make_subplots(specs=[[{\"secondary_y\" : True}]])\n",
    "    color_index = 0\n",
    "    for optim in optimizers:\n",
    "        color = color_cycle[color_index % len(color_cycle)]\n",
    "        color_index += 1\n",
    "        loss_fig.add_trace(go.Scatter(\n",
    "            x=np.arange(0, hp[\"num_epochs\"]+1),\n",
    "            y=train_losses[title][optim],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=color),\n",
    "            name=f\"{optim} Train\",\n",
    "        ), secondary_y=False)\n",
    "        loss_fig.add_trace(go.Scatter(\n",
    "            x=np.arange(0, hp[\"num_epochs\"]+1),\n",
    "            y=val_losses[title][optim],\n",
    "            mode=\"lines+markers\",\n",
    "            line=dict(color=color, dash='dot'),\n",
    "            name=f\"{optim} Validation\",\n",
    "        ), secondary_y=True)\n",
    "    loss_fig.update_layout(\n",
    "        title=f\"{title} training / validation loss\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            tick0=0,\n",
    "            dtick=1,\n",
    "        ),\n",
    "        yaxis_type=\"linear\",\n",
    "    )\n",
    "    loss_fig.update_yaxes(title_text=\"Training Loss\", secondary_y=False)\n",
    "    loss_fig.update_yaxes(title_text=\"Validation Loss\", secondary_y=True)\n",
    "    loss_figures[title] = loss_fig\n",
    "    loss_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:16:55.980107Z",
     "iopub.status.busy": "2024-03-26T15:16:55.979575Z",
     "iopub.status.idle": "2024-03-26T15:16:56.023317Z",
     "shell.execute_reply": "2024-03-26T15:16:56.023215Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gradient norms over epochs for NGD and SGD\n",
    "\n",
    "update_norm_figures = {}\n",
    "\n",
    "color_cycle = ['rgb(0, 0, 255)', 'rgb(255, 0, 0)']\n",
    "\n",
    "for title in models.keys():\n",
    "    update_norm_fig = go.Figure()\n",
    "    color_index = 0\n",
    "    for optim in optimizers:\n",
    "        color = color_cycle[color_index % len(color_cycle)]\n",
    "        color_index += 1\n",
    "        update_norm_fig.add_trace(go.Scatter(\n",
    "            y=all_update_norms[title][optim][::5],\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color),\n",
    "            name=f\"{optim} update norm\"))\n",
    "    update_norm_fig.update_layout(\n",
    "        title=f\"{title} update norms over epochs\",\n",
    "        xaxis_title=\"Steps\",\n",
    "        yaxis_title=\"Update Size\",\n",
    "        yaxis_type=\"linear\",\n",
    "    )\n",
    "    update_norm_figures[title] = update_norm_fig\n",
    "    update_norm_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **4. Perform Hessian rank computation**\n",
    "\n",
    "As a way of verifying results produced by the RLCT, we will compute an approximation of the Hessian for each model at convergence. Then, we'll estimate the rank of this matrix using its eigenspectrum. SLT predicts the following: \n",
    "\n",
    "$\\text{RLCT} \\geq \\frac{\\text{rank}(\\textbf{Hess})}{2}$ \n",
    "\n",
    "We will check whether this is true for our experiments. Hessian computation is done using helper functions from `utils_hessian_fim.py` which acts as a wrapper for the `PyHessian` module (and the `nngeometry` module, for doing computations involving the Fisher Information Matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:16:56.026831Z",
     "iopub.status.busy": "2024-03-26T15:16:56.025826Z",
     "iopub.status.idle": "2024-03-26T15:16:56.311293Z",
     "shell.execute_reply": "2024-03-26T15:16:56.310785Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Hessians for each model - recall that model is a list containing all its past versions\n",
    "if hp[\"hessian\"]:\n",
    "    hessians = {}\n",
    "    for title, model in models.items():\n",
    "        hessian = {}\n",
    "        for optim in optimizers:\n",
    "            hessians_list = produce_hessians(\n",
    "                models=model[optim],\n",
    "                data_loader=train_loader,\n",
    "                num_batches=data_args[\"num_hessian_batches\"],\n",
    "                criterion=criterion,\n",
    "                device=device,\n",
    "            )\n",
    "            hessian[optim] = hessians_list\n",
    "        hessians[title] = hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:16:56.314675Z",
     "iopub.status.busy": "2024-03-26T15:16:56.314142Z",
     "iopub.status.idle": "2024-03-26T15:19:47.532420Z",
     "shell.execute_reply": "2024-03-26T15:19:47.532420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the eigenspectum data from the Hessian objects\n",
    "if hp[\"hessian\"]:\n",
    "    eigenspectra_data = {}\n",
    "    eigenspectra_figs = {}\n",
    "    for title, hessian in hessians.items():\n",
    "        eigenspectrum_data = {}\n",
    "        eigenspectrum_figs = {}\n",
    "        for optim in optimizers:\n",
    "            eigenspectrum_figs_list, eigenspectrum_data_list = produce_eigenspectra(\n",
    "                hessians=hessian[optim],\n",
    "                plot_type=\"log\",\n",
    "            )\n",
    "            eigenspectrum_figs[optim] = eigenspectrum_figs_list\n",
    "            eigenspectrum_data[optim] = eigenspectrum_data_list\n",
    "        eigenspectra_data[title] = eigenspectrum_data\n",
    "        eigenspectra_figs[title] = eigenspectrum_figs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:19:47.536495Z",
     "iopub.status.busy": "2024-03-26T15:19:47.535420Z",
     "iopub.status.idle": "2024-03-26T15:19:47.613795Z",
     "shell.execute_reply": "2024-03-26T15:19:47.613795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Produce the traces of Hessian dimensionality over epochs\n",
    "if hp[\"hessian\"]:\n",
    "    hessian_ranks = {}\n",
    "    for title, eigenspectrum_data in eigenspectra_data.items():\n",
    "        hessian_rank = {}\n",
    "        for optim in optimizers:\n",
    "            hessian_rank_list = find_hessian_dimensionality(eigenspectrum_data[optim])\n",
    "            hessian_rank[optim] = hessian_rank_list\n",
    "        hessian_ranks[title] = hessian_rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **5. Perform RLCT estimation**\n",
    "\n",
    "Using the `devinterp` library, we perform estimation of the RLCT (Real Log Canonical Threshold) or otherwise known as the LLC (Local Learning Coefficient).\n",
    "\n",
    "`rlct_estimates` is a dictionary containing dictionaries, each of which contain two lists, one for SGD RLCT values over epochs, and one for NGD RLCT values over epochs. The same is true for `wbic_estimates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:19:47.613795Z",
     "iopub.status.busy": "2024-03-26T15:19:47.613795Z",
     "iopub.status.idle": "2024-03-26T15:22:57.070665Z",
     "shell.execute_reply": "2024-03-26T15:22:57.070665Z"
    }
   },
   "outputs": [],
   "source": [
    "rlct_estimates = {}\n",
    "histories = {}\n",
    "\n",
    "for title, model in models.items():\n",
    "    history = {}\n",
    "    rlct_estimate = {}\n",
    "    for optim in optimizers:\n",
    "        rlct_list, history_list = estimate_rlcts(\n",
    "            model[optim], train_loader, criterion, device, devinterp_args,\n",
    "        )\n",
    "        rlct_estimate[optim] = rlct_list\n",
    "        history[optim] = history_list\n",
    "    rlct_estimates[title] = rlct_estimate \n",
    "    histories[title] = history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:22:57.070665Z",
     "iopub.status.busy": "2024-03-26T15:22:57.070665Z",
     "iopub.status.idle": "2024-03-26T15:22:57.086317Z",
     "shell.execute_reply": "2024-03-26T15:22:57.086317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute generalisation losses for each model, for SGD and NGD, so we can compare this to the testing loss\n",
    "\n",
    "gen_losses = {}\n",
    "for title in models.keys():\n",
    "    gen_loss = {}\n",
    "    for optim in optimizers:\n",
    "        gen_loss_list = []\n",
    "        for i in range(hp[\"num_epochs\"]):\n",
    "            if histories[title][optim][i] is None:\n",
    "                gen_loss_list.append(None)\n",
    "            else:\n",
    "                gen_loss_list.append(train_losses[title][optim][i] + histories[title][optim][i][\"llc/moving_avg\"][-1][-1]/data_args[\"batch_size\"])\n",
    "        gen_loss[optim] = gen_loss_list\n",
    "    gen_losses[title] = gen_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **6. Visualise RLCT / Hessian rank, Hessian eigenspectra, generalisation loss, RLCT convergence**\n",
    "\n",
    "We display the following final figures:\n",
    "- RLCT and Hessian rank evolution for each model, for NGD and SGD\n",
    "- Hessian eigenspectra for SGD and NGD overlaid on the same plot\n",
    "- Evolution of generalisation loss for each model, compared to validation loss\n",
    "- RLCT moving average evolution for each model, for NGD and SGD, to check for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:22:57.086317Z",
     "iopub.status.busy": "2024-03-26T15:22:57.086317Z",
     "iopub.status.idle": "2024-03-26T15:22:57.118235Z",
     "shell.execute_reply": "2024-03-26T15:22:57.118235Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise RLCT and Hessian rank data\n",
    "\n",
    "exp_figures = {}\n",
    "\n",
    "for title in models.keys():\n",
    "    exp_fig = make_subplots(specs=[[{\"secondary_y\" : True}]])\n",
    "    color_index = 0\n",
    "    for optim in optimizers:\n",
    "        color = color_cycle[color_index % len(color_cycle)]\n",
    "        color_index += 1\n",
    "        exp_fig.add_trace(go.Scatter(\n",
    "            x=epochs,\n",
    "            y=rlct_estimates[title][optim][1:],\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"{optim} RLCT\",\n",
    "            line=dict(color=color),\n",
    "        ), secondary_y=False)\n",
    "        if hp[\"hessian\"]:\n",
    "            exp_fig.add_trace(go.Scatter(\n",
    "                x=epochs,\n",
    "                y=hessian_ranks[title][optim][1:],\n",
    "                mode=\"lines+markers\",\n",
    "                name=f\"{optim} Hessian Rank\",\n",
    "                line=dict(color=color, dash=\"dot\"),\n",
    "            ), secondary_y=True)\n",
    "    exp_fig.update_layout(\n",
    "        title=f\"{title} RLCT / Hessian Rank (optional) evolution during training\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            tick0=0,\n",
    "            dtick=1,\n",
    "        )\n",
    "        yaxis_type=\"linear\",\n",
    "    )\n",
    "    exp_fig.update_yaxes(title_text=\"RLCT\", secondary_y=False)\n",
    "    exp_fig.update_yaxes(title_text=\"Hessian rank\", secondary_y=True)\n",
    "    exp_figures[title] = exp_fig\n",
    "    exp_fig.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:22:57.118235Z",
     "iopub.status.busy": "2024-03-26T15:22:57.118235Z",
     "iopub.status.idle": "2024-03-26T15:22:57.212358Z",
     "shell.execute_reply": "2024-03-26T15:22:57.212358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise converged eigenspectra for SGD and NGD for each model\n",
    "\n",
    "combined_eigenspectra = {}\n",
    "\n",
    "for title in models.keys():\n",
    "\n",
    "    combined_eigenspectrum = go.Figure()\n",
    "    final_eigenspectra = {}\n",
    "    traces = {}\n",
    "\n",
    "    for optim in optimizers:\n",
    "        final_eigenspectra[optim] = eigenspectra_figs[title][optim][-2]\n",
    "        final_eigenspectra[optim].data[0].name = optim\n",
    "        combined_eigenspectrum.add_trace(final_eigenspectra[optim].data[0])\n",
    "\n",
    "    combined_eigenspectrum.update_layout(\n",
    "        title=f\"{title} Hessian eigenspectra at convergence\",\n",
    "        xaxis_title=\"Eigenvalue\",\n",
    "        yaxis_title=\"Probability density (log scale)\",\n",
    "        yaxis_type=\"log\",\n",
    "    )\n",
    "\n",
    "    combined_eigenspectrum.show()\n",
    "    combined_eigenspectra[title] = (combined_eigenspectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:22:57.241354Z",
     "iopub.status.busy": "2024-03-26T15:22:57.240827Z",
     "iopub.status.idle": "2024-03-26T15:22:57.256365Z",
     "shell.execute_reply": "2024-03-26T15:22:57.256365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualise generalisation loss vs. testing loss for each model\n",
    "\n",
    "train_gen_figs = {}\n",
    "for title in models.keys():\n",
    "    train_gen_fig = go.Figure()\n",
    "    color_index = 0\n",
    "    for optim in optimizers:\n",
    "        color = color_cycle[color_index % len(color_cycle)]\n",
    "        color_index += 1\n",
    "        train_gen_fig.add_trace(go.Scatter(\n",
    "            x=epochs,\n",
    "            y=val_losses[title][optim][1:],\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"{optim} Validation\",\n",
    "            line=dict(color=color),\n",
    "        ))\n",
    "        train_gen_fig.add_trace(go.Scatter(\n",
    "            x=epochs,\n",
    "            y=gen_losses[title][optim][1:],\n",
    "            mode=\"lines+markers\",\n",
    "            name=f\"{optim} Generalisation\",\n",
    "            line=dict(color=color, dash=\"dot\"),\n",
    "        ))\n",
    "    train_gen_fig.update_layout(\n",
    "        title=f\"{title} validation / generalisation loss\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        xaxis=dict(\n",
    "            tickmode='linear',\n",
    "            tick0=0,\n",
    "            dtick=1,\n",
    "        )\n",
    "        yaxis_type=\"linear\",\n",
    "    )\n",
    "    train_gen_figs[title] = train_gen_fig\n",
    "    train_gen_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:22:57.258929Z",
     "iopub.status.busy": "2024-03-26T15:22:57.258929Z",
     "iopub.status.idle": "2024-03-26T15:22:57.398349Z",
     "shell.execute_reply": "2024-03-26T15:22:57.398349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the LLC chains converged for each model\n",
    "\n",
    "rlct_converge_plots = {}\n",
    "for title in models.keys():\n",
    "    rlct_converge_plot = go.Figure()\n",
    "    for epoch in epochs:\n",
    "        for optim in optimizers:\n",
    "            if histories[title][optim][epoch] is not None:\n",
    "                rlct_converge_plot.add_trace(go.Scatter(\n",
    "                    y=histories[title][optim][epoch][\"llc/moving_avg\"][0],\n",
    "                    name=f\"{optim} Epoch {epoch}\",\n",
    "                ))\n",
    "    rlct_converge_plot.update_layout(\n",
    "        title=f\"Evolution of LLC moving average for each model over epochs for {title}\",\n",
    "        xaxis_title=\"Draws\",\n",
    "        yaxis_title=\"RLCT\",\n",
    "        yaxis_type=\"linear\",\n",
    "        legend_title=\"Epoch\"\n",
    "    )\n",
    "    rlct_converge_plots[title] = rlct_converge_plot\n",
    "    rlct_converge_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-26T15:22:57.414229Z",
     "iopub.status.busy": "2024-03-26T15:22:57.414229Z",
     "iopub.status.idle": "2024-03-26T15:22:57.652383Z",
     "shell.execute_reply": "2024-03-26T15:22:57.652383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the results to a HTML file.\n",
    "\n",
    "figures = []\n",
    "\n",
    "combined_args = {**hp, **data_args, **devinterp_args}\n",
    "\n",
    "summary = pprint.pformat(combined_args)\n",
    "\n",
    "for fig in loss_figures.values():\n",
    "    figures.append(fig)\n",
    "for fig in update_norm_figures.values():\n",
    "    figures.append(fig)\n",
    "for fig in exp_figures.values():\n",
    "    figures.append(fig)\n",
    "for fig in combined_eigenspectra.values():\n",
    "    figures.append(fig)\n",
    "for fig in train_gen_figs.values():\n",
    "    figures.append(fig)\n",
    "for fig in rlct_converge_plots.values():\n",
    "    figures.append(fig)\n",
    "\n",
    "curr_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M\")\n",
    "\n",
    "write_figs_to_html(\n",
    "    figs=figures,\n",
    "    dest=f\"./ngd_sgd/dnn_ngd_sgd_rlct_{curr_time}.html\",\n",
    "    title=\"Does NGD converge to minima that are 'more complex' i.e. have a higher RLCT?\",\n",
    "    summary=summary,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windows_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
